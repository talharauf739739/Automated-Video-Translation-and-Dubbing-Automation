{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhdmdOHnvjHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4687bdb2-f8c1-41f3-a15d-b7d13ab5310f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.13.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Downloading SpeechRecognition-3.13.0-py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.13.0\n",
            "Collecting os-sys\n",
            "  Downloading os_sys-2.1.4-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting pygubu (from os-sys)\n",
            "  Downloading pygubu-0.35.6-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from os-sys) (2024.2)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.10/dist-packages (from os-sys) (0.5.3)\n",
            "Collecting progress (from os-sys)\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from os-sys) (4.67.1)\n",
            "Collecting progressbar (from os-sys)\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from os-sys) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from os-sys) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from os-sys) (1.17.0)\n",
            "Collecting jupyter (from os-sys)\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from os-sys) (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from os-sys) (4.12.3)\n",
            "Collecting Eel (from os-sys)\n",
            "  Downloading eel-0.18.1.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting extract-zip (from os-sys)\n",
            "  Downloading extract_zip-1.0.0-py3-none-any.whl.metadata (403 bytes)\n",
            "INFO: pip is looking at multiple versions of os-sys to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting os-sys\n",
            "  Downloading os_sys-2.1.3-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Downloading os_sys-2.1.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Downloading os_sys-2.1.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Downloading os_sys-2.1.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Downloading os_sys-2.0.9-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Downloading os_sys-2.0.8-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Downloading os_sys-2.0.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "INFO: pip is still looking at multiple versions of os-sys to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading os_sys-2.0.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "  Downloading os_sys-2.0.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "  Downloading os_sys-2.0.4-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting webview (from os-sys)\n",
            "  Downloading webview-0.1.5.tar.gz (18 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting deepgram-sdk==0.3.0\n",
            "  Downloading deepgram_sdk-0.3.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from deepgram-sdk==0.3.0) (3.11.10)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from deepgram-sdk==0.3.0) (14.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==0.3.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==0.3.0) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==0.3.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==0.3.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==0.3.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==0.3.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==0.3.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk==0.3.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->deepgram-sdk==0.3.0) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->deepgram-sdk==0.3.0) (3.10)\n",
            "Downloading deepgram_sdk-0.3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: deepgram-sdk\n",
            "Successfully installed deepgram-sdk-0.3.0\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803319 sha256=fe983d2cb376a669f439c5d80940a4b5504bc4fff7141bb5c1de776e7e079438\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install os-sys\n",
        "!pip install deepgram-sdk==0.3.0\n",
        "!pip install pydub\n",
        "\n",
        "#!pip uninstall whisper\n",
        "#!pip uninstall openai-whisper\n",
        "!pip install openai-whisper\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To Improve Transcription Let's use: Deepgram-sdk, Wisper and pydub**"
      ],
      "metadata": {
        "id": "jiT0gkxu0fRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5b8b243e83906934f93c55d141d9d95315239b12"
      ],
      "metadata": {
        "id": "fWdae8T939vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def preprocess_audio(wav_path):\n",
        "    # Load the wav file\n",
        "    audio = AudioSegment.from_wav(wav_path)\n",
        "\n",
        "    # Normalize the audio (adjust volume)\n",
        "    normalized_audio = audio.normalize()\n",
        "\n",
        "    # Save the processed file to a new path\n",
        "    processed_wav_path = wav_path.replace(\".wav\", \"_processed.wav\")\n",
        "    normalized_audio.export(processed_wav_path, format=\"wav\")\n",
        "\n",
        "    return processed_wav_path\n",
        "\n",
        "def wav_to_text_whisper(wav_dir, txt_dir):\n",
        "    # Create the output directory if it doesn't exist\n",
        "    if not os.path.exists(txt_dir):\n",
        "        os.mkdir(txt_dir)\n",
        "\n",
        "    # Load the Whisper model\n",
        "    model = whisper.load_model(\"base\")\n",
        "\n",
        "    # Iterate over files in the wav directory\n",
        "    for file in os.listdir(wav_dir):\n",
        "        # Process only .wav files\n",
        "        if file.endswith(\".wav\"):\n",
        "            wav_path = os.path.join(wav_dir, file)\n",
        "\n",
        "            # Preprocess the audio (normalize)\n",
        "            processed_wav_path = preprocess_audio(wav_path)\n",
        "\n",
        "            # Transcribe using Whisper\n",
        "            result = model.transcribe(processed_wav_path)\n",
        "            text = result['text']\n",
        "\n",
        "            # Save transcription\n",
        "            txt_path = os.path.join(txt_dir, file[:-4] + \".txt\")\n",
        "            with open(txt_path, \"w\") as text_file:\n",
        "                text_file.write(text)\n",
        "            print(f\"Transcribed {file} successfully using Whisper.\")\n",
        "\n",
        "def wav_to_text_deepgram(wav_dir, txt_dir, deepgram_api_key):\n",
        "    # Create the output directory if it doesn't exist\n",
        "    if not os.path.exists(txt_dir):\n",
        "        os.mkdir(txt_dir)\n",
        "\n",
        "    # Iterate over files in the wav directory\n",
        "    for file in os.listdir(wav_dir):\n",
        "        # Process only .wav files\n",
        "        if file.endswith(\".wav\"):\n",
        "            wav_path = os.path.join(wav_dir, file)\n",
        "\n",
        "            # Open the audio file for Deepgram transcription\n",
        "            with open(wav_path, 'rb') as f:\n",
        "                response = requests.post(\n",
        "                    f\"https://api.deepgram.com/v1/listen?access_token={deepgram_api_key}\",\n",
        "                    headers={\"Authorization\": f\"Bearer {deepgram_api_key}\"},\n",
        "                    files={\"file\": f}\n",
        "                )\n",
        "                if response.status_code == 200:\n",
        "                    text = response.json()['results']['channels'][0]['alternatives'][0]['transcript']\n",
        "                    txt_path = os.path.join(txt_dir, file[:-4] + \".txt\")\n",
        "                    with open(txt_path, \"w\") as text_file:\n",
        "                        text_file.write(text)\n",
        "                    print(f\"Transcribed {file} successfully using Deepgram.\")\n",
        "                else:\n",
        "                    print(f\"Error transcribing {file} with Deepgram: {response.status_code}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Directory where your .wav files are stored\n",
        "    wav_dir = r\"/content/drive/MyDrive/Dutch wav\"\n",
        "\n",
        "    # Directory where you want to save the transcribed text files\n",
        "    txt_dir = r\"/content/drive/MyDrive/Dutch Transcription\"\n",
        "\n",
        "    # For Deepgram, include your API key\n",
        "    deepgram_api_key = \"5b8b243e83906934f93c55d141d9d95315239b12\"\n",
        "\n",
        "    # Choose whether to use Whisper or Deepgram\n",
        "    wav_to_text_whisper(wav_dir, txt_dir)  # Uncomment this line to use Whisper\n",
        "    # wav_to_text_deepgram(wav_dir, txt_dir, deepgram_api_key)  # Uncomment this line to use Deepgram\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QVs8ISU4P_t",
        "outputId": "4eb78e76-5487-4c62-f67d-3a07c1d32f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 125MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed Dutch_Hockey.wav successfully using Whisper.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "me0vnd5J4rfi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}